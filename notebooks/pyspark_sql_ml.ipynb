{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://app.pluralsight.com/library/courses/spark-2-building-machine-learning-models/table-of-contents\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "file = 'file:///D:/dev/large_dataset/ml-20m/links.csv'\n",
    "file2 = 'file:///D:/dev/large_dataset/ml-20m/movies.csv'\n",
    "\n",
    "#df = spark.read.format(\"csv\").option(\"header\", \"yes\").option(\"inferSchema\", \"true\").load(file)\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(file)\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").load(file2)\n",
    "\n",
    "# df.count()\n",
    "# df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|movieId| imdbId|  tmdbId|\n",
      "+-------+-------+--------+\n",
      "|      1|0114709|  862.11|\n",
      "|      2|0113497| 8844.11|\n",
      "|      3|0113228|15602.11|\n",
      "|      4|0114885|31357.11|\n",
      "|      5|0113041|11862.11|\n",
      "|      6|0113277|  949.11|\n",
      "|      7|0114319|11860.11|\n",
      "|      8|0112302|45325.11|\n",
      "|      9|0114576| 9091.11|\n",
      "|     10|0113189|  710.11|\n",
      "|     11|0112346| 9087.11|\n",
      "|     12|0112896|12110.11|\n",
      "|     13|0112453|21032.11|\n",
      "|     14|0113987|10858.11|\n",
      "|     15|0112760| 1408.11|\n",
      "|     16|0112641|  524.11|\n",
      "|     17|0114388| 4584.11|\n",
      "|     18|0113101|    5.11|\n",
      "|     19|0112281| 9273.11|\n",
      "|     20|0113845|11517.11|\n",
      "+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'spark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-834cba9db5d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select movieId from tview order by movieId DESC\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\root\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m             raise AttributeError(\n\u001b[1;32m-> 1301\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m   1302\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'spark'"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"tview\")\n",
    "df2.createOrReplaceTempView(\"tview2\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|movieId| imdbId|  tmdbId|\n",
      "+-------+-------+--------+\n",
      "|      1|0114709|  862.11|\n",
      "|      2|0113497| 8844.11|\n",
      "|      3|0113228|15602.11|\n",
      "|      4|0114885|31357.11|\n",
      "|      5|0113041|11862.11|\n",
      "|      6|0113277|  949.11|\n",
      "|      7|0114319|11860.11|\n",
      "|      8|0112302|45325.11|\n",
      "|      9|0114576| 9091.11|\n",
      "|     10|0113189|  710.11|\n",
      "+-------+-------+--------+\n",
      "\n",
      "+-------+\n",
      "|movieId|\n",
      "+-------+\n",
      "|  99999|\n",
      "|  99996|\n",
      "|  99994|\n",
      "+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sql = spark.sql(\"select * from tview limit 10\")\n",
    "df_sql.show()\n",
    "df_sql2 = spark.sql(\"select genres from tview2\")\n",
    "#df_sql3 = spark.sql(\"select count(*) from tview2\")\n",
    "df_sql3 = spark.sql(\"select count(*), genres from tview2 group by genres limit 10\")\n",
    "\n",
    "spark.sql(\"select movieId from tview order by movieId DESC\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|              genres|\n",
      "+--------+--------------------+\n",
      "|      27|Comedy|Horror|Thr...|\n",
      "|       6|Adventure|Sci-Fi|...|\n",
      "|       9|Action|Adventure|...|\n",
      "|       4| Action|Drama|Horror|\n",
      "|       4|Comedy|Drama|Horr...|\n",
      "|       2|Action|Animation|...|\n",
      "|       1|Fantasy|Musical|M...|\n",
      "|       1|Adventure|Mystery...|\n",
      "|       2|Animation|Childre...|\n",
      "|      70|Action|Adventure|...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_sql.show()\n",
    "#df_sql2.show()\n",
    "df_sql3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-19a522a1564f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mva\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tmdbId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sql' is not defined"
     ]
    }
   ],
   "source": [
    "df_sql.show()\n",
    "va = VectorAssembler(inputCols=['tmdbId'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'va' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1022870ac08d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mva\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_sql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'va' is not defined"
     ]
    }
   ],
   "source": [
    "cluster = va.transform(df_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
