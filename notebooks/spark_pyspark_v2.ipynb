{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Reading data with spark #\n",
    "\n",
    "#create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession object\n",
    "spark = SparkSession.builder.appName(\"Analyze London\").getOrCreate()\n",
    "\n",
    "# create Spark data frame from csv with spark.read()\n",
    "data = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(r\"D:\\dev\\large_dataset\\spark-2-getting-started\\02\\demos\\datasets\\london_crime_by_lsoa.csv\")\n",
    "\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lsoa_code: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- major_category: string (nullable = true)\n",
      " |-- minor_category: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      "\n",
      "[('lsoa_code', 'string'), ('borough', 'string'), ('major_category', 'string'), ('minor_category', 'string'), ('value', 'string'), ('year', 'string'), ('month', 'string')]\n",
      "<bound method DataFrame.describe of DataFrame[lsoa_code: string, borough: string, major_category: string, minor_category: string, value: string, year: string, month: string]>\n"
     ]
    }
   ],
   "source": [
    "# check data schema for data frame \n",
    "data.printSchema()\n",
    "print(data.dtypes)\n",
    "print(data.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|   borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|   Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646| Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|   Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774| Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004563|Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# count the number of records -\n",
    "\n",
    "# data.count()\n",
    "data.limit(5).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|   borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|   Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646| Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|   Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774| Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004563|Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop rows having na\n",
    "data.dropna()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[borough: string, major_category: string, minor_category: string, value: string, year: string, month: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the columns which are not useful with data.drop(column)\n",
    "data.drop('lsoa_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values with distinct function\n",
    "# select a column and call distinct on it\n",
    "\n",
    "distinct_br = data.select('borough').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             borough|\n",
      "+--------------------+\n",
      "|             Croydon|\n",
      "|          Wandsworth|\n",
      "|              Bexley|\n",
      "|             Lambeth|\n",
      "|Barking and Dagenham|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_br.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+-------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001786|Hackney|     Criminal Damage|Criminal Damage T...|    0|2011|    6|\n",
      "|E01001794|Hackney|Violence Against ...|          Harassment|    1|2013|    2|\n",
      "|E01001787|Hackney|     Criminal Damage|Other Criminal Da...|    0|2011|    7|\n",
      "|E01001738|Hackney|Violence Against ...|        Wounding/GBH|    0|2013|   12|\n",
      "|E01001807|Hackney|  Theft and Handling|  Other Theft Person|    0|2016|    8|\n",
      "+---------+-------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter data - where clause\n",
    "\n",
    "hackney_data = data.filter(data['borough'] == 'Hackney')\n",
    "hackney_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|  borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|  Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646|Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|  Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774|Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004177|   Sutton|  Theft and Handling|Theft/Taking of P...|    1|2016|    8|\n",
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter in clause\n",
    "\n",
    "data_15_16 = data.filter(data['year'].isin(['2015', '2016']))\n",
    "data_15_16.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|    major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+------------------+--------------------+-----+----+-----+\n",
      "|E01003333|            Lewisham|   Criminal Damage|Criminal Damage T...|    0|2016|    1|\n",
      "|E01002915|Kingston upon Thames|Theft and Handling|  Other Theft Person|    0|2016|    2|\n",
      "+---------+--------------------+------------------+--------------------+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter - check just a fraction of data with sample function\n",
    "\n",
    "f01 = data_15_16.sample(fraction=0.000001).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             borough| count|\n",
      "+--------------------+------+\n",
      "|             Croydon|602100|\n",
      "|          Wandsworth|498636|\n",
      "|              Bexley|385668|\n",
      "|             Lambeth|519048|\n",
      "|Barking and Dagenham|311040|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grouping aggregating with ##\n",
    "# group by clause - just like count(*) followed by group by, here it is groupBy('fieldname') and then count() to get the count\n",
    "\n",
    "bcr = data.groupBy('borough').count()\n",
    "bcr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|             borough|value|count|\n",
      "+--------------------+-----+-----+\n",
      "|              Camden|   23|   66|\n",
      "|            Haringey|   18|   31|\n",
      "|          Hillingdon|  131|    1|\n",
      "|            Hounslow|   30|    2|\n",
      "|Kingston upon Thames|   81|    2|\n",
      "|             Hackney|   65|    1|\n",
      "|Barking and Dagenham|    7|  371|\n",
      "|              Barnet|    4| 3983|\n",
      "|      City of London|    2|   84|\n",
      "|              Camden|   26|   49|\n",
      "|           Southwark|   23|   31|\n",
      "|Kingston upon Thames|   33|   12|\n",
      "|            Havering|   30|    5|\n",
      "|      Waltham Forest|   25|    8|\n",
      "|Kingston upon Thames|   31|   10|\n",
      "|          Hillingdon|  102|    1|\n",
      "|             Croydon|   45|    2|\n",
      "|         Westminster|  217|    1|\n",
      "|              Sutton|    1|43870|\n",
      "|               Brent|    5| 2422|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group by for more than on field at at iem\n",
    "\n",
    "bcr = data.groupBy(['borough', 'value']).count()\n",
    "bcr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             borough|sum(value)|\n",
      "+--------------------+----------+\n",
      "|             Croydon|  260294.0|\n",
      "|          Wandsworth|  204741.0|\n",
      "|              Bexley|  114136.0|\n",
      "|             Lambeth|  292178.0|\n",
      "|Barking and Dagenham|  149447.0|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use group by with other aggregations like sum with .agg function.\n",
    "# so like in SQL call sum on a value and then aggregate it in backwareds order\n",
    "# here sum is a built in function\n",
    "\n",
    "bcr = data.groupBy('borough').agg( {\"value\":\"sum\"} )\n",
    "bcr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|        v|\n",
      "+---------+\n",
      "|  Croydon|\n",
      "|Greenwich|\n",
      "|  Bromley|\n",
      "|Redbridge|\n",
      "+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a column and select it with as in sql - withColumnName\n",
    "#select a as b - withColumnRenamed('borough', 'X')\n",
    "\n",
    "data.select('borough').withColumnRenamed('borough','v').show(4)\n",
    "\n",
    "# same for the above\n",
    "\n",
    "bcr = data.groupBy('borough').agg({\"value\":\"sum\"}).withColumnRenamed('borough', 'X')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(value)|\n",
      "+----------+\n",
      "| 6447758.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select sum(a,v,b) without a group by\n",
    "data.agg({'value': 'sum'}).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_conv = data.collect()[0][0]\n",
    "################################################\n",
    "#  collect function \n",
    "\n",
    "import pyspark.sql.functions as func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             borough|value|\n",
      "+--------------------+-----+\n",
      "|Barking and Dagenham|    1|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|             borough|value|\n",
      "+--------------------+-----+\n",
      "|Barking and Dagenham|    1|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|             borough|value|\n",
      "+--------------------+-----+\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    0|\n",
      "|Barking and Dagenham|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# func has round method - round(number, 2) - will round of to two decimal places\n",
    "# orderBy\n",
    "data.select(['borough', 'value']).orderBy('borough', ).show(4) # order by a column\n",
    "\n",
    "data.select(['borough', 'value']).orderBy('borough', ascending=True).show(4) # order by a column ASC\n",
    "\n",
    "data.select(['borough', 'value']).orderBy('borough', desc=True).show(4) # order by a column DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|month|sum(value)|\n",
      "+-----+----------+\n",
      "|    7|   58564.0|\n",
      "|   11|   59704.0|\n",
      "|    3|   57669.0|\n",
      "|    8|   55641.0|\n",
      "|    5|   56327.0|\n",
      "|    6|   57039.0|\n",
      "|    9|   56933.0|\n",
      "|    1|   55515.0|\n",
      "|   10|   60537.0|\n",
      "|    4|   53467.0|\n",
      "+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select count(*), convictions, months group by con, months where year = 1020\n",
    "\n",
    "data.filter(data['year']==2014).groupBy('month').agg({\"value\" : \"sum\"}).show(10)\n",
    "\n",
    "#GROUP BY ALWAYS NEED AGGREGATION\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|min(year)|\n",
      "+---------+\n",
      "|     2008|\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|max(year)|\n",
      "+---------+\n",
      "|     2016|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### more aggregation  and plotting #######\n",
    "\n",
    "data.select('year').agg({\"year\":\"min\"}).show()\n",
    "data.select('year').agg({\"year\":\"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|max(year)|\n",
      "+---------+\n",
      "|     2016|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('year').agg({\"year\":\"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lsoa_code', 'string'),\n",
       " ('borough', 'string'),\n",
       " ('major_category', 'string'),\n",
       " ('minor_category', 'string'),\n",
       " ('value', 'string'),\n",
       " ('year', 'string'),\n",
       " ('month', 'string')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sp_help - dtypes\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------+\n",
      "|Drugs|borough_major_category|\n",
      "+-----+----------------------+\n",
      "|32616|              Havering|\n",
      "|29160|                Merton|\n",
      "|35424|              Haringey|\n",
      "|37368|         Tower Hamlets|\n",
      "|42336|               Bromley|\n",
      "|44064|               Enfield|\n",
      "|22140|  Kingston upon Thames|\n",
      "|32616|           Westminster|\n",
      "|23004|  Richmond upon Thames|\n",
      "|43740|              Lewisham|\n",
      "+-----+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data.describe - will show min, max, count, etc on the frame- like in pandas\n",
    "\n",
    "# to get information in matrix form: - crosstab function\n",
    "# crosstab - pair wise frequency table of given columns\n",
    "\n",
    "data.crosstab('borough', 'major_category').select('Drugs', 'borough_major_category').show(10)\n",
    "#data.crosstab('borough', 'major_category').select('Drugs', 'Robbery', 'Burglary').show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ accumulators & broadcast variables ######################\n",
    "\n",
    "# Scala utilies closures - function pointers\n",
    "# function can return another function as return value\n",
    "# input argument to a function can also be a function\n",
    "\n",
    "# what is closure:\n",
    "# if there is a nested function, then inner function has access to the variable in the outter function\n",
    "# this access persist even if the outter function scope as vanished\n",
    "# Note: the inner function can is called directly from outside \n",
    "\n",
    "# these called inner functions carry the copies of the local variable of the outter functions with them around\n",
    "# this is called closure\n",
    "\n",
    "####>>>> closure -> boradcast -> accumulators => # in the notes #\n",
    "\n",
    "# from pyspark.sql.functions import broadcast\n",
    "# from pyspark.sql.functions import udf -> user defined functions\n",
    "\n",
    "\n",
    "# usually peform join operations with broadcast for efficiencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using broadcast\n",
    "\n",
    "import pyspark.sql\n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "\n",
    "ss = SparkSession.builder.appName(\"X\").getOrCreate()\n",
    "# RFOL - read format options load\n",
    "d1 = ss.read\\\n",
    "    .format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .load(r\"D:\\dev\\large_dataset\\spark-2-getting-started\\02\\demos\\datasets\\player.csv\")\n",
    "\n",
    "d2 = ss.read.format('csv').option('header', 'true').load(r\"D:\\dev\\large_dataset\\spark-2-getting-started\\02\\demos\\datasets\\player_attributes.csv\")\n",
    "\n",
    "# d2id = d2.select('id').show(4) - broken fix it\n",
    "# d1.select('id').join(d2id,'id', 'inner')\n",
    "\n",
    "# create Spark data frame from csv with spark.read()\n",
    "# borad\n",
    "\n",
    "# d2.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### saving data frames \n",
    "\n",
    "# coalesce - function to repartition data frame to write out to the file - argument 1 does that\n",
    "# if you pass 2 to the coalesce function then each partion will write out a single file.\n",
    "\n",
    "# due to coalesce function all the partitions are merged together and only file is written \n",
    "d1.select('id').coalesce(1)\\\n",
    ".write\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(r\"d:/dev/a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will write multiple files, as many data partions were there\n",
    "d1.select('id') \\\n",
    ".write\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(r\"d:/dev/a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SPARK SQL #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "########################### HOW TO CREATE SPARK CONTEXT #####################\n",
    "######## BUT YOU DO NOT NEED THIS. ###########################################\n",
    "sc = spark.sparkContext\n",
    "\n",
    "########//########//########//########//########// Register the DataFrame as a SQL temporary view\n",
    "d1.createOrReplaceTempView(\"tbl1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## runing a sql on the dataframe\n",
    "\n",
    "# with spark session sql context is already available, use it directly\n",
    "# YOU DO NOT NEED SQL CONTEXT TO QUERY - SS CAN DO IT DIRECTLY AS LONG AS THE DATAFRAM IS REGISTERED AS A TABLE.\n",
    "print(type(ss)) \n",
    "ss.sql(\"select id, player_name, birthday from tbl1\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "############### registering the table as global table - available for all the sessions ####\n",
    "###########################################################################################\n",
    "\n",
    "# d1.createOrReplaceTempView(\"d1\")\n",
    "d1.createOrReplaceGlobalTempView(\"gt\")\n",
    "print(type(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO ACCESS global tables you need absolute name like \n",
    "#### global_temp.<table_name>\n",
    "\n",
    "ss.sql(\"select * from global_temp.gt\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.select('id').write.save(r'd:/dev/new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss.read.format('json').option().load(r\"D:\\dev\\large_dataset\\simple_json.json\")\n",
    "jd = spark.read.json(r\"D:\\dev\\large_dataset\\simple_json.json\")\n",
    "jd.show(4)\n",
    "jd.schema\n",
    "jd.category.schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
